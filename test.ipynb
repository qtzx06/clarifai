{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "601d1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'text': \"Large language models often waste time generating redundant reasoning steps like reflections and transitions, which hurt efficiency and accuracy. SEAL tackles this by analyzing the model's latent space to identify and steer its reasoning process.\", 'animation': \"Visualize a neural network's latent space with clusters representing different thought types (execution in blue, reflection in red, transition in green), showing clear separation between them.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfac4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Large language models often waste time generating redundant reasoning steps like reflections and transitions, which hurt efficiency and accuracy. SEAL tackles this by analyzing the model's latent space to identify and steer its reasoning process.\",\n",
       " 'animation': \"Visualize a neural network's latent space with clusters representing different thought types (execution in blue, reflection in red, transition in green), showing clear separation between them.\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, step in enumerate(len(dict['text']()), 1):\n",
    "    print(i, dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3808309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<>:1: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "/var/folders/bg/jxfsmn692bgcdtynd6zrsylr0000gn/T/ipykernel_38306/2078704983.py:1: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  [{'text': \"Large language models often waste time generating redundant reasoning steps like reflections and transitions, which hurt efficiency and accuracy. SEAL tackles this by analyzing the model's latent space to identify and steer its reasoning process.\", 'animation': \"Visualize a neural network's latent space with clusters representing different thought types (execution in blue, reflection in red, transition in green), showing clear separation between them.\"}, {'text': 'By categorizing thoughts into execution, reflection, and transition types, SEAL extracts a steering vector from the latent space. This vector acts as a guide to suppress unproductive reasoning paths during generation.', 'animation': 'Show a 3D graph where the steering vector (arrow) points away from reflection/transition clusters toward the execution cluster, illustrating directional intervention.'}, {'text': 'During inference, SEAL dynamically adjusts hidden states using the steering vector. This training-free method reduces token usage by 11-50% while improving accuracy by up to 11% across math and coding tasks.', 'animation': \"Compare two timelines: vanilla CoT generation with excessive tokens vs. SEAL's streamlined output, highlighting token savings and correct answer alignment.\"}] ['SEAL (Steerable rEAsoning caLibration)', 'chain-of-thought (CoT) reasoning', 'latent space', 'reasoning steering vector', 'execution/reflection/transition thoughts', 'training-free approach', 'latent space intervention', 'representation engineering', 't-SNE visualization']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLarge language models often waste time generating redundant reasoning steps like reflections and transitions, which hurt efficiency and accuracy. SEAL tackles this by analyzing the model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms latent space to identify and steer its reasoning process.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manimation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVisualize a neural network\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms latent space with clusters representing different thought types (execution in blue, reflection in red, transition in green), showing clear separation between them.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBy categorizing thoughts into execution, reflection, and transition types, SEAL extracts a steering vector from the latent space. This vector acts as a guide to suppress unproductive reasoning paths during generation.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manimation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mShow a 3D graph where the steering vector (arrow) points away from reflection/transition clusters toward the execution cluster, illustrating directional intervention.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDuring inference, SEAL dynamically adjusts hidden states using the steering vector. This training-free method reduces token usage by 11-50\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m while improving accuracy by up to 11\u001b[39;49m\u001b[38;5;132;43;01m% a\u001b[39;49;00m\u001b[38;5;124;43mcross math and coding tasks.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manimation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCompare two timelines: vanilla CoT generation with excessive tokens vs. SEAL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms streamlined output, highlighting token savings and correct answer alignment.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSEAL (Steerable rEAsoning caLibration)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchain-of-thought (CoT) reasoning\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatent space\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreasoning steering vector\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexecution/reflection/transition thoughts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining-free approach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatent space intervention\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrepresentation engineering\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt-SNE visualization\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "[{'text': \"Large language models often waste time generating redundant reasoning steps like reflections and transitions, which hurt efficiency and accuracy. SEAL tackles this by analyzing the model's latent space to identify and steer its reasoning process.\", 'animation': \"Visualize a neural network's latent space with clusters representing different thought types (execution in blue, reflection in red, transition in green), showing clear separation between them.\"}, {'text': 'By categorizing thoughts into execution, reflection, and transition types, SEAL extracts a steering vector from the latent space. This vector acts as a guide to suppress unproductive reasoning paths during generation.', 'animation': 'Show a 3D graph where the steering vector (arrow) points away from reflection/transition clusters toward the execution cluster, illustrating directional intervention.'}, {'text': 'During inference, SEAL dynamically adjusts hidden states using the steering vector. This training-free method reduces token usage by 11-50% while improving accuracy by up to 11% across math and coding tasks.', 'animation': \"Compare two timelines: vanilla CoT generation with excessive tokens vs. SEAL's streamlined output, highlighting token savings and correct answer alignment.\"}] ['SEAL (Steerable rEAsoning caLibration)', 'chain-of-thought (CoT) reasoning', 'latent space', 'reasoning steering vector', 'execution/reflection/transition thoughts', 'training-free approach', 'latent space intervention', 'representation engineering', 't-SNE visualization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d375bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
