"""
Analysis API endpoints for paper concept extraction and clarification
"""
import uuid
from typing import Dict, Any, List
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

from ...models.paper import ConceptResponse, Concept
from ...services.gemini_service import GeminiService
from .upload import papers_db  # Import shared papers database

router = APIRouter()

# Initialize services
gemini_service = GeminiService()

class AnalyzeRequest(BaseModel):
    paper_id: str

class ClarifyRequest(BaseModel):
    text_snippet: str
    context: str = ""

@router.post("/papers/{paper_id}/analyze")
async def analyze_paper(paper_id: str) -> Dict[str, str]:
    """
    Trigger analysis of an uploaded paper
    """
    if paper_id not in papers_db:
        raise HTTPException(status_code=404, detail="Paper not found")
    
    paper = papers_db[paper_id]
    
    if not paper.content:
        raise HTTPException(status_code=400, detail="Paper content not available. Upload may still be processing.")
    
    try:
        # Analyze paper with Gemini (this will also extract concepts)
        print(f"üîç Starting analysis for paper: {paper.title}")
        analysis_result = await gemini_service.analyze_paper_with_gemini(
            content=paper.content,
            title=paper.title
        )
        
        print(f"üîç Raw analysis concepts: {len(analysis_result['concepts'])} concepts")
        for concept in analysis_result["concepts"]:
            print(f"   - '{concept.get('name', 'NO_NAME')}': {concept.get('description', 'NO_DESC')[:50]}...")
        
        # Light filtering - only remove obvious generic/fallback concepts
        valid_concepts_data = []
        for concept_data in analysis_result["concepts"]:
            name = concept_data.get("name", "")
            description = concept_data.get("description", "")
            
            # Only filter out obvious generic patterns
            is_generic = (
                not name or not description or
                len(name) <= 3 or len(description) <= 10 or
                # Only catch the most obvious generic patterns
                name.lower().startswith("key concept from") or
                "temporarily unavailable" in description.lower() or
                "clear, descriptive name" in description.lower()
            )
            
            if not is_generic:
                valid_concepts_data.append(concept_data)
                print(f"‚úÖ Valid analysis concept: '{name}'")
            else:
                print(f"‚ùå Filtered out generic analysis concept: '{name}'")
        
        # Convert concepts to proper format
        paper.concepts = []
        for concept_data in valid_concepts_data:
            concept = Concept(
                id=str(uuid.uuid4()),
                name=concept_data["name"],
                description=concept_data["description"],
                importance_score=concept_data["importance_score"],
                page_numbers=[],
                text_snippets=[],
                related_concepts=[],
                mathematical_visualization=concept_data.get("mathematical_visualization", False)
            )
            paper.concepts.append(concept)
        
        # Update other analysis results
        paper.insights = analysis_result["insights"]
        paper.methodology = analysis_result["methodology"]
        paper.full_analysis = analysis_result["full_analysis"]
        
        print(f"‚úÖ Analysis completed for paper: {paper.title}")
        
        return {
            "message": "Analysis completed successfully",
            "concepts_extracted": len(paper.concepts),
            "insights_generated": len(paper.insights)
        }
        
    except Exception as e:
        print(f"‚ùå Analysis failed for paper {paper_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")

@router.get("/papers/{paper_id}/concepts")
async def get_paper_concepts(paper_id: str) -> ConceptResponse:
    """
    Get extracted concepts for a paper
    """
    if paper_id not in papers_db:
        raise HTTPException(status_code=404, detail="Paper not found")
    
    paper = papers_db[paper_id]
    
    return ConceptResponse(
        concepts=paper.concepts,
        total_count=len(paper.concepts)
    )

@router.post("/papers/{paper_id}/clarify")
async def clarify_text(paper_id: str, request: ClarifyRequest) -> Dict[str, str]:
    """
    Get clarification for specific text from a paper
    """
    if paper_id not in papers_db:
        raise HTTPException(status_code=404, detail="Paper not found")
    
    paper = papers_db[paper_id]
    
    try:
        # Use Gemini to clarify the text
        explanation = await gemini_service.clarify_text_with_gemini(
            text=request.text_snippet,
            context=f"Paper title: {paper.title}. {request.context}"
        )
        
        return {
            "text_snippet": request.text_snippet,
            "explanation": explanation,
            "paper_title": paper.title
        }
        
    except Exception as e:
        print(f"‚ùå Clarification failed: {e}")
        raise HTTPException(status_code=500, detail=f"Clarification failed: {str(e)}")

@router.get("/papers/{paper_id}/insights")
async def get_paper_insights(paper_id: str) -> Dict[str, Any]:
    """
    Get key insights from paper analysis
    """
    if paper_id not in papers_db:
        raise HTTPException(status_code=404, detail="Paper not found")
    
    paper = papers_db[paper_id]
    
    return {
        "paper_id": paper_id,
        "paper_title": paper.title,
        "insights": paper.insights,
        "methodology": paper.methodology,
        "analysis_summary": paper.full_analysis[:500] + "..." if len(paper.full_analysis) > 500 else paper.full_analysis,
        "concepts_count": len(paper.concepts)
    }

@router.post("/papers/{paper_id}/extract-concepts")
async def extract_concepts(paper_id: str) -> ConceptResponse:
    """
    Re-extract or refresh concepts for a paper using Gemini
    """
    if paper_id not in papers_db:
        raise HTTPException(status_code=404, detail="Paper not found")
    
    paper = papers_db[paper_id]
    
    if not paper.content:
        raise HTTPException(status_code=400, detail="Paper content not available")
    
    try:
        # Extract concepts using Gemini
        concepts_data = await gemini_service.generate_concepts_with_gemini(paper.content)
        
        print(f"üîç Raw concepts from Gemini: {len(concepts_data)} concepts")
        for concept in concepts_data:
            print(f"   - '{concept.get('name', 'NO_NAME')}': {concept.get('description', 'NO_DESC')[:50]}...")
        
        # Light filtering - only remove obvious generic/fallback concepts
        valid_concepts_data = []
        for concept_data in concepts_data:
            name = concept_data.get("name", "")
            description = concept_data.get("description", "")
            
            # Only filter out obvious generic patterns
            is_generic = (
                not name or not description or
                len(name) <= 3 or len(description) <= 10 or
                # Only catch the most obvious generic patterns
                name.lower().startswith("key concept from") or
                "temporarily unavailable" in description.lower() or
                "clear, descriptive name" in description.lower()
            )
            
            if not is_generic:
                valid_concepts_data.append(concept_data)
                print(f"‚úÖ Valid concept: '{name}'")
            else:
                print(f"‚ùå Filtered out generic concept: '{name}'")
        
        # Convert to Concept objects
        paper.concepts = []
        for concept_data in valid_concepts_data:
            concept = Concept(
                id=str(uuid.uuid4()),
                name=concept_data["name"],
                description=concept_data["description"],
                importance_score=concept_data["importance_score"],
                page_numbers=[],
                text_snippets=[],
                related_concepts=[],
                mathematical_visualization=concept_data.get("mathematical_visualization", False)
            )
            paper.concepts.append(concept)
        
        print(f"üîÑ Concepts refreshed for paper: {paper.title} ({len(paper.concepts)} valid concepts)")
        
        return ConceptResponse(
            concepts=paper.concepts,
            total_count=len(paper.concepts)
        )
        
    except Exception as e:
        print(f"‚ùå Concept extraction failed: {e}")
        raise HTTPException(status_code=500, detail=f"Concept extraction failed: {str(e)}")

@router.post("/papers/{paper_id}/generate-additional-concept")
async def generate_additional_concept(paper_id: str) -> Dict[str, Any]:
    """
    Generate ONE additional concept for a paper, considering existing concepts
    """
    if paper_id not in papers_db:
        raise HTTPException(status_code=404, detail="Paper not found")
    
    paper = papers_db[paper_id]
    
    if not paper.content:
        raise HTTPException(status_code=400, detail="Paper content not available")
    
    try:
        # Get existing concept names to avoid duplicates
        existing_concept_names = [c.name for c in paper.concepts]
        
        print(f"üîç Generating additional concept beyond existing: {existing_concept_names}")
        
        # Generate ONE additional concept using Gemini
        new_concept_data = await gemini_service.generate_additional_concept_with_gemini(
            content=paper.content,
            existing_concepts=existing_concept_names
        )
        
        if new_concept_data:
            # Create new concept object
            new_concept = Concept(
                id=str(uuid.uuid4()),
                name=new_concept_data["name"],
                description=new_concept_data["description"],
                importance_score=new_concept_data["importance_score"],
                page_numbers=[],
                text_snippets=[],
                related_concepts=[],
                mathematical_visualization=new_concept_data.get("mathematical_visualization", False)
            )
            
            # Add to existing concepts (don't replace)
            paper.concepts.append(new_concept)
            
            print(f"‚úÖ Generated additional concept: '{new_concept.name}'")
            
            return {
                "success": True,
                "new_concept": {
                    "id": new_concept.id,
                    "name": new_concept.name,
                    "description": new_concept.description,
                    "importance_score": new_concept.importance_score,
                    "mathematical_visualization": new_concept.mathematical_visualization
                },
                "total_concepts": len(paper.concepts)
            }
        else:
            raise HTTPException(status_code=500, detail="Failed to generate additional concept")
        
    except Exception as e:
        print(f"‚ùå Additional concept generation failed: {e}")
        raise HTTPException(status_code=500, detail=f"Additional concept generation failed: {str(e)}")

@router.get("/papers/{paper_id}/summary")
async def get_paper_summary(paper_id: str) -> Dict[str, Any]:
    """
    Get a comprehensive summary of the paper analysis
    """
    if paper_id not in papers_db:
        raise HTTPException(status_code=404, detail="Paper not found")
    
    paper = papers_db[paper_id]
    
    # Calculate concept importance distribution
    importance_distribution = {
        "high": len([c for c in paper.concepts if c.importance_score >= 0.8]),
        "medium": len([c for c in paper.concepts if 0.6 <= c.importance_score < 0.8]),
        "low": len([c for c in paper.concepts if c.importance_score < 0.6])
    }
    
    return {
        "paper_id": paper_id,
        "title": paper.title,
        "authors": paper.authors,
        "abstract": paper.abstract,
        "concepts_summary": {
            "total_concepts": len(paper.concepts),
            "importance_distribution": importance_distribution,
            "top_concepts": [
                {"name": c.name, "score": c.importance_score} 
                for c in sorted(paper.concepts, key=lambda x: x.importance_score, reverse=True)[:3]
            ]
        },
        "insights_count": len(paper.insights),
        "methodology": paper.methodology,
        "analysis_status": paper.analysis_status.value,
        "video_status": paper.video_status.value
    }